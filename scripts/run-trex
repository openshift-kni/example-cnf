#!/usr/bin/env python3

# https://github.com/secdev/scapy/blob/master/scapy/layers/l2.py#L164

from trex.stl.api import *
from trex.common.trex_logger import Logger

import subprocess
import signal
import sys
import time
import json
from datetime import datetime
import sys
import logging
import re
import queue
from threading import Thread
import os
import string
import random

from kubernetes import client, config, watch
from kubernetes.client.rest import ApiException
from dateutil import parser
from datetime import datetime
from dateutil.tz import tzutc

log = logging.getLogger('run-trex')
log.setLevel(logging.DEBUG)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

fh = logging.FileHandler('/var/log/run-trex.log')
fh.setLevel(logging.INFO)
fh.setFormatter(formatter)

fhd = logging.FileHandler('/var/log/trex.log')
fhd.setLevel(logging.DEBUG)
fhd.setFormatter(formatter)

st = logging.StreamHandler()
st.setLevel(logging.INFO)

log.addHandler(fh)
log.addHandler(fhd)
log.addHandler(st)


class CustomLogger(Logger):
    def __init__ (self, verbose="error"):
        super(CustomLogger, self).__init__(verbose)
        self.msg = ''
        self.force_exit = False

    def _write (self, msg, newline):
        if not self.force_exit:
            ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            if isinstance(msg, (str, bytes)):
                msg = ansi_escape.sub('', msg)
                self.msg += msg
            if newline:
                log.debug(self.msg)
                self.msg = ''

    def _flush (self):
        pass

clog = CustomLogger("debug")


class STLS1(object):

    def __init__ (self, ports, size, rate, duration=-1, verbose="debug"):
        self.client = STLClient(verbose_level=verbose, logger=clog)
        self.fsize = 64
        self.pg_id = 0
        self.pkt_type = "ether"
        self.num_streams = 1
        self.ipack = [0] * len(ports)
        self.opack = [0] * len(ports)
        self.miss = []
        self.force_exit = False
        self.ports = ports
        self.port_a = ports[0]
        self.port_b = ports[1]
        self.size =size
        self.rate = rate
        self.duration = duration
        self.queue = queue.Queue(maxsize=0)
        signal.signal(signal.SIGINT, self.signal_handler)
        self.event_notified_miss = False

    def create_stream (self, dest_mac=None):
        size = self.fsize - 4; # HW will add 4 bytes ethernet CRC

        ethr = Ether(dst=dest_mac) / IP(src = "16.0.0.1", dst = "48.0.0.1") / UDP(dport = 12, sport = 1025)
        vlan = Ether() / Dot1Q(vlan=11) / IP(src = "16.0.0.1", dst = "48.0.0.1") / UDP(dport = 12, sport = 1025)
        qinq = Ether(type=0x88A8) / Dot1Q(vlan=19) / Dot1Q(vlan=11) / IP(src = "16.0.0.1", dst = "48.0.0.1") / UDP(dport = 12, sport = 1025)

        pkt_types = {
            "ether": ethr,
            "vlan": vlan,
            "qinq": qinq
        }

        if self.pkt_type not in pkt_types.keys():
            log.info ("Wrong pkt_type given. Allowed values are " + format(pkt_types.keys()))
            return []

        pad = max(0, size - len(self.pkt_type)) * 'x'
        pkt = STLPktBuilder(pkt = pkt_types[self.pkt_type]/pad)

        streams = []
        for pg_id_add in range(0, self.num_streams):
            streams.append(STLStream(packet = pkt, mode = STLTXCont(pps=1), flow_stats = STLFlowStats(pg_id = self.pg_id + pg_id_add)))

        return streams

    def stats(self, stat, ports):
        for i in ports:
            if  stat[i]['ipackets'] <= 0 or  stat[i]['opackets'] <= 0:
                return

        for i in ports:
            ipack = stat[i]['ipackets'] - self.ipack[i]
            opack = stat[i]['opackets'] - self.opack[i]
            self.ipack[i] = stat[i]['ipackets']
            self.opack[i] = stat[i]['opackets']
        if ipack >= opack:
            log.info("MATCH: out(%s) > in(%s)" % (opack, ipack))
            self.notify_event(False)
            if self.miss and not self.miss[-1].get('end'):
                self.miss[-1]['end'] = datetime.now()
                log.info("Loss recovery: %s" % (self.miss[-1]['end'] - self.miss[-1]['start']))
        else:
            log.info("MISS:  out(%s) > in(%s)" % (opack, ipack))
            self.notify_event(True)
            if self.miss and not self.miss[-1].get('end'):
                self.miss.append({'start': datetime.now()})

    def notify_event(self, miss=False):
        if self.event_notified_miss != miss:
            data = {}
            now = datetime.now()
            data['microtime'] = now.strftime('%Y-%m-%dT%H:%M:%S.%fZ')
            data['time'] = now.strftime('%Y-%m-%dT%H:%M:%S.%fZ')
            if miss:
                data['msg'] = ("Packet miss started")
                data['reason'] = 'PacketDropped'
            else:
                data['msg'] = ("Packet miss recovered")
                data['reason'] = 'PacketMatched'
            log.info("Post Event: %s at %s" % (data['reason'], data['microtime']))
            Thread(target=self.create_event, args=[data]).start()
            self.event_notified_miss = miss

    def create_event(self, data):
        group = "examplecnf.openshift.io"
        version = "v1"
        namespace = "example-cnf"
        plural = "trexconfigs"

        try:
            custom_api = client.CustomObjectsApi()
            objs = custom_api.list_namespaced_custom_object(group, version, namespace, plural)
        except ApiException as e:
            log.info("Exception when calling CustomObjectsApi->list_namespaced_custom_object: %s\n" % e)
            return

        if len(objs['items']) == 0:
            log.info("no trexconfig objects")
            return

        trex_config_name = objs['items'][0]['metadata']['name']
        trex_config_uid = objs['items'][0]['metadata']['uid']
        trex_config_api_version = objs['items'][0]['apiVersion']

        evtTimeMicro = data['microtime']
        evtTime = data['time']
        evtName = trex_config_name + '-' + ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))

        cr = { 	'apiVersion': 'events.k8s.io/v1beta1',
		'kind': 'Event',
                'metadata': {
                   'name': evtName,
                   'namespace': namespace,
                   'ownerReferences': []
                },
                'type': 'Normal',
                'eventTime': evtTimeMicro,
                'deprecatedLastTimestamp': evtTime,
                'deprecatedFirstTimestamp': evtTime,
	        'reason': data['reason'],
                'action': data['reason'],
                'note': data['msg'],
                'regarding': {
                        'namespace': namespace,
                        'kind': 'TRexConfig',
                        'name': trex_config_name,
                        'uid': trex_config_uid
                    },
                'reportingController': 'pod/' + os.environ['HOSTNAME'],
                'reportingInstance': trex_config_name
	     }

        cr['metadata']['ownerReferences'].append({
                'apiVersion': trex_config_api_version,
                'kind': 'TRexConfig',
                'name': trex_config_name,
                'uid': trex_config_uid,
                'controller': True
            })

        events_api = client.EventsV1beta1Api()
        try:
            resp = events_api.create_namespaced_event(namespace, cr)
        except ApiException as e:
            log.info("Exception on creating Event: %s\n" % e)

    def start_watch(self):
        process = Thread(target=self.watch_cr, args=[])
        process.start()

    def watch_cr(self):
        group = "examplecnf.openshift.io"
        version = "v1"
        namespace = "example-cnf"
        plural = "testpmdmacs"

        config.load_incluster_config()
        custom_api = client.CustomObjectsApi()
        w = watch.Watch()
        now = datetime.utcnow().replace(tzinfo=tzutc())
        for event in w.stream(custom_api.list_cluster_custom_object,
                              group=group, version=version, plural=plural):
            if event['type'] == 'ADDED':
                meta = event['object']['metadata']
                spec = event['object']['spec']
                created = parser.parse(meta['creationTimestamp'])
                if created > now:
                    self.queue.put(event['object'])

    def get_macs(self, spec):
        macs = []
        for resource in spec['resources']:
            for device in resource['devices']:
                macs.append(device['mac'])
        log.info("macs list - %s" % ",".join(macs))
        return macs

    def update(self, obj):
        meta = obj['metadata']
        spec = obj['spec']
        log.info("Name(%s) Namespace(%s)" % (meta['name'], meta['namespace']))
        macs = self.get_macs(spec)
        if len(macs) < len(self.ports):
            log.info("ERROR: macs len(%s) is less then ports len (%s)" % (len(macs), len(self.ports)))
            return

        log.info("reset ports")
        self.client.reset(ports=self.ports)
        log.info("create stream with new mac address")
        for idx in range(0, len(self.ports)):
            self.add_streams(self.ports[idx], macs[idx])
        log.info("staring ports")
        self.client.start(ports=self.ports, mult=self.rate, duration=self.duration, core_mask=STLClient.CORE_MASK_PIN)
        data = {}
        now = datetime.now()
        data['microtime'] = now.strftime('%Y-%m-%dT%H:%M:%S.%fZ')
        data['time'] = now.strftime('%Y-%m-%dT%H:%M:%S.%fZ')
        data['msg'] = ("Packet stream is updated wit new destination mac address: %s" % ','.join(macs))
        data['reason'] = 'StreamUpdated'
        self.create_event(data)

    def add_streams(self, port, dest_mac):
        if dest_mac:
            log.info("create stream for port %s with dest mac %s" % (port, dest_mac))
        new_stream = self.create_stream(dest_mac)
        self.client.add_streams(new_stream, [port])

    def init_streams(self):
        with open('/etc/trex_cfg.yaml') as f:
            cfg = yaml.safe_load(f)
        for idx in range(0, len(self.ports)):
            self.add_streams(self.ports[idx], cfg[0]['port_info'][idx]['dest_mac'])

    def simple_burst(self):
        passed = True
        try:
            # connect to server
            self.client.connect()

            # prepare our ports
            self.client.reset(ports = self.ports)

            self.init_streams()

            # clear the stats before injecting
            self.client.clear_stats()

            # here we multiply the traffic lineaer to whatever given in rate
            log.info("Running {:} on ports {:}, {:} for 10 seconds...".format(self.rate, self.port_a, self.port_b))
            self.client.start(ports = self.ports,
                mult = self.rate,
                duration = self.duration,
                core_mask = STLClient.CORE_MASK_PIN
            )
            self.start_watch()

            if self.duration == -1:
                while True:
                    self.stats(self.client.get_stats(), ports = self.ports)
                    try:
                        obj = self.queue.get_nowait()
                        self.update(obj)
                    except queue.Empty:
                        pass
                    if self.force_exit:
                        break
                    time.sleep(1)
            else:
                # block until done
                self.client.wait_on_traffic(ports=self.ports)

            # read the stats after the test
            stats = self.client.get_stats()

            log.info(json.dumps(stats[self.port_a], indent = 4, separators=(',', ': '), sort_keys = True))
            log.info(json.dumps(stats[self.port_b], indent = 4, separators=(',', ': '), sort_keys = True))

            lost_a = stats[self.port_a]["opackets"] - stats[self.port_b]["ipackets"]
            lost_b = stats[self.port_b]["opackets"] - stats[self.port_a]["ipackets"]

            log.info("\npackets lost from {0} --> {1}:   {2} pkts".format(self.port_a, self.port_b, lost_a))
            log.info("packets lost from {0} --> {1}:   {2} pkts".format(self.port_b, self.port_a, lost_b))

            if self.client.get_warnings():
                log.info("\n\n*** test had warnings ****\n\n")
                for w in self.client.get_warnings():
                    log.info(w)

            if (lost_a == 0) and (lost_b == 0) and not self.client.get_warnings():
                passed = True
            else:
                passed = False

        except STLError as e:
            passed = False
            log.info(e)

        finally:
            self.force_exit = True
            self.client.disconnect()

        if passed:
            print("\nTest has passed :-)\n")
        else:
            print("\nTest has failed :-(\n")

    def signal_handler(self, sig, frame):
        log.info('You pressed Ctrl+C!')
        time.sleep(6)
        self.force_exit = True
        clog.force_exit = True
        sys.exit(0)


def main():
    # run the tests
    packet_size = os.getenv("PACKET_SIZE") or 64
    packet_rate = os.getenv("PACKET_RATE") or "10pps"
    duration = os.getenv("DURATION") or -1
    if duration != -1:
        duration = int(duration)
    log.info("Starting burst...")
    log.info("Packet Size - %s" % packet_size)
    log.info("Packet Rate - %s" % packet_rate)
    if duration == -1:
        log.info("Packets will be generated forever...")
    try:
        obj = STLS1(ports = [0, 1], size=packet_size, rate=packet_rate, duration=duration)
        obj.simple_burst()
    except Exception as e:
        log.exception("failed to start burst: %s" % e)

if __name__ == "__main__":
    main()
